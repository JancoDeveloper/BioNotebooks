{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhbs7i4szF4f"
      },
      "source": [
        "# LTR Example Machine Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JgGBty_zF4j"
      },
      "source": [
        "# Importación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cpg-Ga3zF4k"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from pandas import set_option\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#import seaborn as sns; sns.set() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nShQqWj66QkB",
        "outputId": "aeeb992b-caa7-4580-b864-3b7e461c6f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIkYNkKpzF4l"
      },
      "source": [
        "# Lectura de Archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-x18nXQzF4m",
        "outputId": "eef73d4e-54d5-415a-ec98-8f4600ece617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label   B1   B2   B3   B4   B5   B6   B7   B8   B9  ... B15991 B15992  \\\n",
              "0        0  100  011  100  100  001  001  011  001  100  ...    000    000   \n",
              "1        5  100  011  100  100  011  011  011  011  100  ...    000    000   \n",
              "2        5  100  011  100  001  011  011  011  011  100  ...    000    000   \n",
              "3        1  100  011  100  001  001  011  001  001  001  ...    000    000   \n",
              "4        2  100  011  001  001  001  010  010  011  011  ...    000    000   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
              "1003    10  100  011  100  100  011  010  011  011  001  ...    000    000   \n",
              "1004    10  100  011  100  100  011  010  011  011  001  ...    000    000   \n",
              "1005    10  100  011  100  100  011  010  011  011  001  ...    000    000   \n",
              "1006    10  100  011  010  100  010  001  100  011  100  ...    000    000   \n",
              "1007    10  100  011  100  010  001  001  011  011  011  ...    000    000   \n",
              "\n",
              "     B15993 B15994 B15995 B15996 B15997 B15998 B15999 B16000  \n",
              "0       000    000    000    000    000    000    000    000  \n",
              "1       000    000    000    000    000    000    000    000  \n",
              "2       000    000    000    000    000    000    000    000  \n",
              "3       000    000    000    000    000    000    000    000  \n",
              "4       000    000    000    000    000    000    000    000  \n",
              "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "1003    000    000    000    000    000    000    000    000  \n",
              "1004    000    000    000    000    000    000    000    000  \n",
              "1005    000    000    000    000    000    000    000    000  \n",
              "1006    000    000    000    000    000    000    000    000  \n",
              "1007    000    000    000    000    000    000    000    000  \n",
              "\n",
              "[1008 rows x 16001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1df05d5-def4-412b-9d5b-864c4ce5e030\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>...</th>\n",
              "      <th>B15991</th>\n",
              "      <th>B15992</th>\n",
              "      <th>B15993</th>\n",
              "      <th>B15994</th>\n",
              "      <th>B15995</th>\n",
              "      <th>B15996</th>\n",
              "      <th>B15997</th>\n",
              "      <th>B15998</th>\n",
              "      <th>B15999</th>\n",
              "      <th>B16000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>010</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>100</td>\n",
              "      <td>010</td>\n",
              "      <td>001</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>010</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1008 rows × 16001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1df05d5-def4-412b-9d5b-864c4ce5e030')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1df05d5-def4-412b-9d5b-864c4ce5e030 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1df05d5-def4-412b-9d5b-864c4ce5e030');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "set_option(\"display.max_rows\", 10)\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "\n",
        "filename = '/content/drive/MyDrive/!UNAL/Introducción a las ciencias computacionales/Notebooks/Data/LTR-COD1.csv'\n",
        "training_data = pd.read_csv(filename,delimiter=',',dtype='str')\n",
        "training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WRlfqCWzF4n"
      },
      "source": [
        "# Estadísticas Básicas de los datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdGnjBpCzF4n",
        "outputId": "636ecd3e-bcb3-4b58-9a77-eb0361bba9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Label    B1    B2    B3    B4    B5    B6    B7    B8    B9  ...  \\\n",
              "count   1008  1008  1008  1008  1008  1008  1008  1008  1008  1008  ...   \n",
              "unique    14     4     4     4     4     4     4     4     4     4  ...   \n",
              "top        0   100   011   100   100   011   001   011   001   001  ...   \n",
              "freq      72   890   922   620   653   482   379   461   404   290  ...   \n",
              "\n",
              "       B15991 B15992 B15993 B15994 B15995 B15996 B15997 B15998 B15999 B16000  \n",
              "count    1008   1008   1008   1008   1008   1008   1008   1008   1008   1008  \n",
              "unique      1      1      1      1      1      1      1      1      1      1  \n",
              "top       000    000    000    000    000    000    000    000    000    000  \n",
              "freq     1008   1008   1008   1008   1008   1008   1008   1008   1008   1008  \n",
              "\n",
              "[4 rows x 16001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a01f3e4a-4d6a-4fcb-8361-e5a9890b9c23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>...</th>\n",
              "      <th>B15991</th>\n",
              "      <th>B15992</th>\n",
              "      <th>B15993</th>\n",
              "      <th>B15994</th>\n",
              "      <th>B15995</th>\n",
              "      <th>B15996</th>\n",
              "      <th>B15997</th>\n",
              "      <th>B15998</th>\n",
              "      <th>B15999</th>\n",
              "      <th>B16000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>...</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>72</td>\n",
              "      <td>890</td>\n",
              "      <td>922</td>\n",
              "      <td>620</td>\n",
              "      <td>653</td>\n",
              "      <td>482</td>\n",
              "      <td>379</td>\n",
              "      <td>461</td>\n",
              "      <td>404</td>\n",
              "      <td>290</td>\n",
              "      <td>...</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "      <td>1008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 16001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a01f3e4a-4d6a-4fcb-8361-e5a9890b9c23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a01f3e4a-4d6a-4fcb-8361-e5a9890b9c23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a01f3e4a-4d6a-4fcb-8361-e5a9890b9c23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "training_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0oMPV7mzF4p"
      },
      "source": [
        "# Separación de clase y características"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3OrOkTzC6Kw",
        "outputId": "9222ad29-e4ca-4ff5-be7a-12953c260d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT4cTeW4zF4q"
      },
      "outputs": [],
      "source": [
        "labels = training_data['Label'].values\n",
        "features= training_data.drop(['Label'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqDU9jUIzF4q",
        "outputId": "7bfe5a09-7d2a-4008-f2cb-8005ee4939bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "labels.astype('int').min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAeth1cKzF4r",
        "outputId": "58db3c54-bd2a-41a4-c6d6-0553e8d53f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       B1   B2   B3   B4   B5   B6   B7   B8   B9  B10  ... B15991 B15992  \\\n",
              "0     100  011  100  100  001  001  011  001  100  100  ...    000    000   \n",
              "1     100  011  100  100  011  011  011  011  100  001  ...    000    000   \n",
              "2     100  011  100  001  011  011  011  011  100  001  ...    000    000   \n",
              "3     100  011  100  001  001  011  001  001  001  001  ...    000    000   \n",
              "4     100  011  001  001  001  010  010  011  011  010  ...    000    000   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
              "1003  100  011  100  100  011  010  011  011  001  010  ...    000    000   \n",
              "1004  100  011  100  100  011  010  011  011  001  010  ...    000    000   \n",
              "1005  100  011  100  100  011  010  011  011  001  010  ...    000    000   \n",
              "1006  100  011  010  100  010  001  100  011  100  001  ...    000    000   \n",
              "1007  100  011  100  010  001  001  011  011  011  010  ...    000    000   \n",
              "\n",
              "     B15993 B15994 B15995 B15996 B15997 B15998 B15999 B16000  \n",
              "0       000    000    000    000    000    000    000    000  \n",
              "1       000    000    000    000    000    000    000    000  \n",
              "2       000    000    000    000    000    000    000    000  \n",
              "3       000    000    000    000    000    000    000    000  \n",
              "4       000    000    000    000    000    000    000    000  \n",
              "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "1003    000    000    000    000    000    000    000    000  \n",
              "1004    000    000    000    000    000    000    000    000  \n",
              "1005    000    000    000    000    000    000    000    000  \n",
              "1006    000    000    000    000    000    000    000    000  \n",
              "1007    000    000    000    000    000    000    000    000  \n",
              "\n",
              "[1008 rows x 16000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34f28da6-df55-42bb-a027-ed6aeece53e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>B6</th>\n",
              "      <th>B7</th>\n",
              "      <th>B8</th>\n",
              "      <th>B9</th>\n",
              "      <th>B10</th>\n",
              "      <th>...</th>\n",
              "      <th>B15991</th>\n",
              "      <th>B15992</th>\n",
              "      <th>B15993</th>\n",
              "      <th>B15994</th>\n",
              "      <th>B15995</th>\n",
              "      <th>B15996</th>\n",
              "      <th>B15997</th>\n",
              "      <th>B15998</th>\n",
              "      <th>B15999</th>\n",
              "      <th>B16000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>010</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>010</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>010</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>001</td>\n",
              "      <td>010</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>100</td>\n",
              "      <td>010</td>\n",
              "      <td>001</td>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>001</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>100</td>\n",
              "      <td>011</td>\n",
              "      <td>100</td>\n",
              "      <td>010</td>\n",
              "      <td>001</td>\n",
              "      <td>001</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>011</td>\n",
              "      <td>010</td>\n",
              "      <td>...</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "      <td>000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1008 rows × 16000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34f28da6-df55-42bb-a027-ed6aeece53e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34f28da6-df55-42bb-a027-ed6aeece53e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34f28da6-df55-42bb-a027-ed6aeece53e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEJP3A_4zF4o"
      },
      "source": [
        "# Imputación de datos (de ser necesario!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj_NZxJEzF4o",
        "outputId": "12102621-efcc-409a-bf8f-060ac6142879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[100.,  11., 100., ...,   0.,   0.,   0.],\n",
              "       [100.,  11., 100., ...,   0.,   0.,   0.],\n",
              "       [100.,  11., 100., ...,   0.,   0.,   0.],\n",
              "       ...,\n",
              "       [100.,  11., 100., ...,   0.,   0.,   0.],\n",
              "       [100.,  11.,  10., ...,   0.,   0.,   0.],\n",
              "       [100.,  11., 100., ...,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "imputer = imputer.fit(features)\n",
        "features = imputer.transform(features)\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLybsSizF4r"
      },
      "source": [
        "# Descomposición en componentes principales (de ser necesario!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1DnTDZ6zF4r",
        "outputId": "3a8deb9c-f9fa-47da-dbc5-e23a97e0d964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-8.43298778e+02,  2.26676880e+02,  4.04980573e+02, ...,\n",
              "        -3.20635884e+01,  4.93995828e+01,  2.00355531e+01],\n",
              "       [ 7.52943679e+02, -1.75740704e+02, -6.38178202e+02, ...,\n",
              "         8.21713329e+01, -1.36297962e+02,  5.30008428e-02],\n",
              "       [ 7.54055806e+02, -2.05054127e+02, -5.96179416e+02, ...,\n",
              "         6.31386284e+01,  3.66508070e+01, -1.35625138e+02],\n",
              "       ...,\n",
              "       [-7.84903631e+02,  1.88091141e+02,  1.49139629e+02, ...,\n",
              "         2.26547941e+01,  3.53034767e+00,  4.16859326e+01],\n",
              "       [-4.39447488e+02,  2.60533763e+02, -1.83290368e+02, ...,\n",
              "         4.18492592e+01, -1.77198695e+00, -9.14069178e+01],\n",
              "       [-7.19478502e+02,  1.80355213e+02,  6.01172597e+01, ...,\n",
              "        -4.97929831e+01, -2.38113119e+01,  9.03396215e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA(n_components=100)\n",
        "pca.fit(features)\n",
        "features_PCA = pca.transform(features)\n",
        "features_PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape, features_PCA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxgyFtBoGJ4k",
        "outputId": "a32c0b0c-26ea-4979-ade5-a0af9e28f595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1008, 16000), (1008, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4VXpy8kzF4r"
      },
      "source": [
        "# Escalamiento del vector de características (de ser necesario!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CSM4ufazF4s"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(features)\n",
        "features_scaler = scaler.transform(features)\n",
        "#desde el PCA\n",
        "scaler = preprocessing.StandardScaler().fit(features_PCA)\n",
        "features_scaler_PCA = scaler.transform(features_PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isu-ZzkCzF4s"
      },
      "source": [
        "# Segmentación de los datos para entrenamiento y pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LO9ZQqczF4s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "validation_size = 0.2\n",
        "seed = 0\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(features_PCA, labels, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn5o-ErKzF4s",
        "outputId": "b5c3fa15-daa2-41b5-823c-62f8edab8bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((806, 100), (806,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train.shape,Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PvMCJ3YzF4t",
        "outputId": "0257f76b-ebcd-49ce-e6a1-0dad0b599daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -504.23648227,   583.21218074,   177.26179779, ...,\n",
              "           53.50979477,   -37.26811866,    66.19310152],\n",
              "       [ -332.11086376,   587.53283459,   -20.26574455, ...,\n",
              "          -47.9094104 ,   -40.79811207,    52.5249469 ],\n",
              "       [-1427.67788515, -1162.13032586,  -478.08347963, ...,\n",
              "            2.66442269,   -26.06517373,   -14.6012238 ],\n",
              "       ...,\n",
              "       [ 1029.5546613 ,   229.51689542,  -800.33115803, ...,\n",
              "           58.8311993 ,  -111.77155774,  -165.71844937],\n",
              "       [ 1757.0171427 ,  -502.86809235,    18.02509185, ...,\n",
              "         -314.28028555,   387.55727451,   -96.79206743],\n",
              "       [-1372.52857338, -1089.31420116,  -318.31641305, ...,\n",
              "           67.85692632,    27.49712047,   -74.17206438]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train[0 :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmI6hTpCzF4u"
      },
      "source": [
        "# 1. Algoritmo de KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI7uYJGUzF4u"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier()\n",
        "KNN.fit(X_train, Y_train)\n",
        "predictions = KNN.predict(X_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD_kOnSjzF4u"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFQ2UlXFzF4u"
      },
      "outputs": [],
      "source": [
        "def accuracy(conf):\n",
        "    total_correct = 0.\n",
        "    nb_classes = conf.shape[0]\n",
        "    for i in np.arange(0,nb_classes):\n",
        "        total_correct += conf[i][i]\n",
        "    acc = total_correct/sum(sum(conf))\n",
        "    return acc\n",
        "\n",
        "def resultados(Y_validation,predictions):\n",
        "    conf = confusion_matrix(Y_validation, predictions)\n",
        "    print ('Flow Pattern classification accuracy = %f' % accuracy(conf))\n",
        "\n",
        "    print ('Accuracy:', accuracy_score(Y_validation, predictions))\n",
        "    print ('F1 score:', f1_score(Y_validation, predictions,average='weighted'))\n",
        "    print ('Recall:', recall_score(Y_validation, predictions,\n",
        "                              average='weighted'))\n",
        "    print ('Precision:', precision_score(Y_validation, predictions,\n",
        "                                    average='weighted'))\n",
        "    print ('\\n clasification report:\\n', classification_report(Y_validation, predictions))\n",
        "    print ('\\n confussion matrix:\\n',confusion_matrix(Y_validation, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkSvkGsdzF4v",
        "outputId": "290fc638-9ea7-4133-c6e7-ac1897ea6efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.475248\n",
            "Accuracy: 0.4752475247524752\n",
            "F1 score: 0.4550222320233057\n",
            "Recall: 0.4752475247524752\n",
            "Precision: 0.5832606338741175\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.62      0.48        13\n",
            "           1       0.33      0.38      0.35         8\n",
            "          10       0.39      0.64      0.49        14\n",
            "          11       0.86      1.00      0.93        19\n",
            "          12       0.32      0.43      0.36        14\n",
            "          13       0.71      0.59      0.65        17\n",
            "           2       0.67      0.09      0.16        22\n",
            "           3       0.20      0.08      0.11        13\n",
            "           4       0.71      0.33      0.45        15\n",
            "           5       0.26      0.92      0.40        12\n",
            "           6       0.25      0.38      0.30         8\n",
            "           7       0.75      0.40      0.52        15\n",
            "           8       0.73      0.61      0.67        18\n",
            "           9       1.00      0.14      0.25        14\n",
            "\n",
            "    accuracy                           0.48       202\n",
            "   macro avg       0.54      0.47      0.44       202\n",
            "weighted avg       0.58      0.48      0.46       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 8  1  0  0  1  0  0  0  1  1  1  0  0  0]\n",
            " [ 2  3  1  0  0  0  0  0  1  1  0  0  0  0]\n",
            " [ 1  0  9  0  1  0  0  0  0  3  0  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  2  0  1  6  0  0  1  0  1  0  0  1  0]\n",
            " [ 0  1  1  1  2 10  0  0  0  1  1  0  0  0]\n",
            " [ 0  0  1  0  2  1  2  0  0 12  3  1  0  0]\n",
            " [ 3  0  3  0  3  0  0  1  0  0  0  1  2  0]\n",
            " [ 1  2  0  0  1  0  0  2  5  2  2  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0 11  0  0  0  0]\n",
            " [ 0  0  3  0  0  0  0  0  0  2  3  0  0  0]\n",
            " [ 1  0  1  1  2  1  1  0  0  1  0  6  1  0]\n",
            " [ 2  0  3  0  1  0  0  1  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  0  2  0  0  0  8  2  0  0  2]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibHyiCJQzF4v"
      },
      "source": [
        "# 2. Algoritmo de LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvhTiydzzF4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a0f21e-3aeb-42d2-ae2c-7ca7de4be735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X_train, Y_train)\n",
        "predictions = LR.predict(X_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP2g8nGrzF4v"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElcRCT8LzF4w",
        "outputId": "31f791ba-bf99-4822-f513-db1815fd4cd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.376238\n",
            "Accuracy: 0.37623762376237624\n",
            "F1 score: 0.38092492058647476\n",
            "Recall: 0.37623762376237624\n",
            "Precision: 0.40003361923134784\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.54      0.56        13\n",
            "           1       0.08      0.12      0.10         8\n",
            "          10       0.36      0.29      0.32        14\n",
            "          11       0.80      0.84      0.82        19\n",
            "          12       0.17      0.21      0.19        14\n",
            "          13       0.36      0.29      0.32        17\n",
            "           2       0.38      0.23      0.29        22\n",
            "           3       0.22      0.31      0.26        13\n",
            "           4       0.25      0.27      0.26        15\n",
            "           5       0.58      0.58      0.58        12\n",
            "           6       0.14      0.25      0.18         8\n",
            "           7       0.50      0.27      0.35        15\n",
            "           8       0.29      0.28      0.29        18\n",
            "           9       0.56      0.64      0.60        14\n",
            "\n",
            "    accuracy                           0.38       202\n",
            "   macro avg       0.38      0.37      0.36       202\n",
            "weighted avg       0.40      0.38      0.38       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 7  2  0  0  1  0  0  1  1  0  1  0  0  0]\n",
            " [ 0  1  0  0  1  0  1  2  2  0  0  1  0  0]\n",
            " [ 0  0  4  0  0  1  2  1  0  1  0  0  3  2]\n",
            " [ 0  0  2 16  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 1  1  0  2  3  2  1  0  1  1  1  0  1  0]\n",
            " [ 1  0  1  0  4  5  0  0  2  0  0  1  0  3]\n",
            " [ 0  0  1  1  2  0  5  2  1  1  6  1  1  1]\n",
            " [ 0  2  1  0  1  1  0  4  0  0  0  0  4  0]\n",
            " [ 2  1  0  0  2  0  0  2  4  2  1  0  0  1]\n",
            " [ 0  0  1  0  0  0  0  1  0  7  2  0  1  0]\n",
            " [ 0  0  0  0  1  2  1  1  0  0  2  0  1  0]\n",
            " [ 0  1  0  1  1  1  2  1  2  0  1  4  1  0]\n",
            " [ 1  3  1  0  2  0  0  3  3  0  0  0  5  0]\n",
            " [ 0  2  0  0  0  1  1  0  0  0  0  1  0  9]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ri5JY6nzF4w"
      },
      "source": [
        "# 3. Algoritmo LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnsxwoe6zF4w"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "LDA = LinearDiscriminantAnalysis()\n",
        "LDA.fit(X_train, Y_train)\n",
        "predictions = LDA.predict(X_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6arDH2qKzF4w"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y73Yh7B4zF4w",
        "outputId": "f28f5610-c76a-4ca8-9c9b-cd7d222c4c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.524752\n",
            "Accuracy: 0.5247524752475248\n",
            "F1 score: 0.5270999242487647\n",
            "Recall: 0.5247524752475248\n",
            "Precision: 0.5702199591323063\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.62      0.53        13\n",
            "           1       0.33      0.50      0.40         8\n",
            "          10       0.50      0.57      0.53        14\n",
            "          11       0.79      1.00      0.88        19\n",
            "          12       0.23      0.36      0.28        14\n",
            "          13       0.70      0.41      0.52        17\n",
            "           2       0.62      0.36      0.46        22\n",
            "           3       0.27      0.23      0.25        13\n",
            "           4       0.44      0.27      0.33        15\n",
            "           5       0.57      0.67      0.62        12\n",
            "           6       0.18      0.38      0.24         8\n",
            "           7       0.86      0.40      0.55        15\n",
            "           8       0.73      0.61      0.67        18\n",
            "           9       0.80      0.86      0.83        14\n",
            "\n",
            "    accuracy                           0.52       202\n",
            "   macro avg       0.54      0.52      0.51       202\n",
            "weighted avg       0.57      0.52      0.53       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 8  1  0  0  2  0  0  0  0  0  2  0  0  0]\n",
            " [ 2  4  0  0  0  0  0  0  1  1  0  0  0  0]\n",
            " [ 0  0  8  0  1  0  3  0  0  1  1  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  3  5  0  1  1  1  0  1  0  1  0]\n",
            " [ 0  1  1  1  3  7  0  1  1  0  0  0  0  2]\n",
            " [ 0  0  1  0  2  2  8  1  0  1  6  1  0  0]\n",
            " [ 2  2  1  0  3  0  0  3  0  0  0  0  2  0]\n",
            " [ 1  1  1  0  0  0  0  5  4  1  1  0  0  1]\n",
            " [ 0  0  2  0  1  0  0  0  0  8  1  0  0  0]\n",
            " [ 0  0  1  0  1  0  1  0  1  1  3  0  0  0]\n",
            " [ 1  0  0  1  3  0  0  0  1  0  2  6  1  0]\n",
            " [ 3  2  1  0  1  0  0  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  1  0  0  0 12]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyHSvXSNzF4x"
      },
      "source": [
        "# 4. Algoritmo NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO0VYjr3zF4x"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "NB = GaussianNB()\n",
        "NB.fit(X_train, Y_train)\n",
        "predictions = NB.predict(X_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8awxw_8NzF4x"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpSXw3U1zF4x",
        "outputId": "99bb4cfe-8d05-4517-85b7-2da6f89e2d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.346535\n",
            "Accuracy: 0.3465346534653465\n",
            "F1 score: 0.32417165968038325\n",
            "Recall: 0.3465346534653465\n",
            "Precision: 0.42449569831202233\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.38      0.33        13\n",
            "           1       0.33      0.12      0.18         8\n",
            "          10       0.11      0.07      0.09        14\n",
            "          11       0.78      0.95      0.86        19\n",
            "          12       0.00      0.00      0.00        14\n",
            "          13       0.25      0.24      0.24        17\n",
            "           2       0.58      0.32      0.41        22\n",
            "           3       0.16      0.77      0.27        13\n",
            "           4       0.38      0.20      0.26        15\n",
            "           5       1.00      0.17      0.29        12\n",
            "           6       0.17      0.25      0.20         8\n",
            "           7       0.33      0.20      0.25        15\n",
            "           8       0.75      0.17      0.27        18\n",
            "           9       0.44      0.79      0.56        14\n",
            "\n",
            "    accuracy                           0.35       202\n",
            "   macro avg       0.40      0.33      0.30       202\n",
            "weighted avg       0.42      0.35      0.32       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 5  0  0  0  0  1  0  4  2  0  1  0  0  0]\n",
            " [ 1  1  0  0  0  0  0  4  0  0  0  1  0  1]\n",
            " [ 2  0  1  0  0  0  1  6  0  0  1  2  0  1]\n",
            " [ 1  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  3  0  3  0  6  0  0  0  0  0  1]\n",
            " [ 1  2  1  1  0  4  0  3  0  0  1  0  0  4]\n",
            " [ 0  0  1  0  0  3  7  2  1  0  3  1  1  3]\n",
            " [ 2  0  0  0  0  0  1 10  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  1  1  0  7  3  0  0  1  0  1]\n",
            " [ 1  0  4  0  0  1  0  0  1  2  1  0  0  2]\n",
            " [ 0  0  1  0  0  2  1  1  0  0  2  0  0  1]\n",
            " [ 0  0  1  1  0  1  1  7  0  0  1  3  0  0]\n",
            " [ 2  0  0  0  0  0  0 11  1  0  0  1  3  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  2  0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaYnJIV4zF4x"
      },
      "source": [
        "# 5. Algoritmo SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnKL8a4azF4x"
      },
      "source": [
        "# Escalamiento del vector de características "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG2FSqxHzF4x"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
        "feature_vectors = scaler.transform(feature_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7abwSwzF4y"
      },
      "source": [
        "# Segmentación de los datos para entrenamiento y pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgceuxk4zF4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "validation_size = 0.2\n",
        "seed = 0\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(feature_vectors, correct_FlowPattern_labels, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe1mofmpzF4y"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYY9wP0_zF4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVM = SVC()\n",
        "SVM.fit(X_train, Y_train)\n",
        "predictions = SVM.predict(X_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8PbNnF9zF4y"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACR1HHT8zF4y",
        "outputId": "9efb9352-05c8-48b4-9aaf-e15765be05bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.529703\n",
            "Accuracy: 0.5297029702970297\n",
            "F1 score: 0.5267165109355735\n",
            "Recall: 0.5297029702970297\n",
            "Precision: 0.6265047790409999\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.54      0.47        13\n",
            "           1       0.33      0.38      0.35         8\n",
            "          10       0.73      0.57      0.64        14\n",
            "          11       0.83      1.00      0.90        19\n",
            "          12       0.30      0.43      0.35        14\n",
            "          13       1.00      0.35      0.52        17\n",
            "           2       0.91      0.45      0.61        22\n",
            "           3       0.45      0.38      0.42        13\n",
            "           4       0.50      0.07      0.12        15\n",
            "           5       0.73      0.67      0.70        12\n",
            "           6       0.15      0.50      0.23         8\n",
            "           7       0.71      0.33      0.45        15\n",
            "           8       0.58      0.61      0.59        18\n",
            "           9       0.50      1.00      0.67        14\n",
            "\n",
            "    accuracy                           0.53       202\n",
            "   macro avg       0.58      0.52      0.50       202\n",
            "weighted avg       0.63      0.53      0.53       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 7  1  0  0  2  0  0  1  0  0  2  0  0  0]\n",
            " [ 2  3  0  0  0  0  0  0  1  0  1  0  0  1]\n",
            " [ 0  0  8  0  1  0  1  0  0  1  2  0  0  1]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  2  6  0  0  1  0  0  3  0  1  1]\n",
            " [ 1  1  1  1  3  6  0  0  0  0  1  0  0  3]\n",
            " [ 1  0  0  0  1  0 10  0  0  0  6  1  0  3]\n",
            " [ 1  1  0  0  3  0  0  5  0  0  1  0  2  0]\n",
            " [ 2  2  0  0  0  0  0  4  1  1  3  0  1  1]\n",
            " [ 0  0  1  0  0  0  0  0  0  8  1  0  0  2]\n",
            " [ 0  0  1  0  0  0  0  0  0  1  4  0  1  1]\n",
            " [ 0  0  0  1  3  0  0  0  0  0  2  5  3  1]\n",
            " [ 3  1  0  0  1  0  0  0  0  0  1  1 11  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-81RyM1zF4y"
      },
      "source": [
        "# 5.1 Algoritmo SVM con optimización de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vcM7nkrzF4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "22e43260-c666-4e1d-c20c-cf3c7d114342"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#model selection takes a few minutes, change this variable\n",
        "#to true to run the parameter loop\n",
        "do_model_selection = True\n",
        "\n",
        "if do_model_selection:\n",
        "    C_range = np.array([.01, 1, 5, 10, 20, 50, 100, 1000, 5000, 10000])\n",
        "    gamma_range = np.array([0.000001, 0.001, 0.01, 0.1, 1, 10])\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 2,\n",
        "                     sharex='col', sharey='row',figsize=(10,10))\n",
        "    plot_number = 0\n",
        "    for outer_ind, gamma_value in enumerate(gamma_range):\n",
        "        row = int(plot_number / 2)\n",
        "        column = int(plot_number % 2)\n",
        "        cv_errors = np.zeros(C_range.shape)\n",
        "        train_errors = np.zeros(C_range.shape)\n",
        "        for index, c_value in enumerate(C_range):\n",
        "                                                     \n",
        "            clf = SVC(C=c_value, gamma=gamma_value)\n",
        "            clf.fit(X_train,Y_train)\n",
        "                                                             \n",
        "            train_conf = confusion_matrix(Y_train, clf.predict(X_train))\n",
        "            cv_conf = confusion_matrix(Y_validation, clf.predict(X_validation))\n",
        "                                                                     \n",
        "            cv_errors[index] = accuracy(cv_conf)\n",
        "            train_errors[index] = accuracy(train_conf)\n",
        "                                                                             \n",
        "        ax = axes[row, column]\n",
        "        ax.set_title('Gamma = %g'%gamma_value)\n",
        "        ax.semilogx(C_range, cv_errors, label='CV error')\n",
        "        ax.semilogx(C_range, train_errors, label='Train error')\n",
        "        plot_number += 1\n",
        "        ax.set_ylim([0.2,1])\n",
        "                                                                                             \n",
        "    ax.legend(bbox_to_anchor=(1.05, 0), loc='lower left', borderaxespad=0.)\n",
        "    fig.text(0.5, 0.03, 'C value', ha='center',\n",
        "             fontsize=14)\n",
        "    \n",
        "    fig.text(0.04, 0.5, 'Classification Accuracy', va='center',\n",
        "             rotation='vertical', fontsize=14)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_XuWtiVzF4z"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVM = SVC(C=10, gamma=1e-6)\n",
        "SVM.fit(X_train, Y_train)\n",
        "predictions = SVM.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd-AWsbCzF4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437f6a9d-73a6-43c7-b66d-bb7ed91f5fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.490099\n",
            "Accuracy: 0.4900990099009901\n",
            "F1 score: 0.46779552424773546\n",
            "Recall: 0.4900990099009901\n",
            "Precision: 0.5785496532109352\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.62      0.57        13\n",
            "           1       0.67      0.50      0.57         8\n",
            "          10       0.73      0.57      0.64        14\n",
            "          11       0.86      1.00      0.93        19\n",
            "          12       0.36      0.36      0.36        14\n",
            "          13       0.00      0.00      0.00        17\n",
            "           2       1.00      0.09      0.17        22\n",
            "           3       0.42      0.38      0.40        13\n",
            "           4       0.78      0.47      0.58        15\n",
            "           5       0.75      0.50      0.60        12\n",
            "           6       0.16      0.38      0.22         8\n",
            "           7       0.56      0.33      0.42        15\n",
            "           8       0.65      0.72      0.68        18\n",
            "           9       0.26      1.00      0.41        14\n",
            "\n",
            "    accuracy                           0.49       202\n",
            "   macro avg       0.55      0.49      0.47       202\n",
            "weighted avg       0.58      0.49      0.47       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 8  0  0  0  1  0  0  1  1  0  2  0  0  0]\n",
            " [ 0  4  0  0  0  0  0  1  0  0  1  1  0  1]\n",
            " [ 1  0  8  0  0  0  0  0  0  1  1  0  0  3]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  1  5  1  0  1  0  0  2  0  1  2]\n",
            " [ 0  1  1  1  2  0  0  2  0  0  1  0  0  9]\n",
            " [ 1  0  0  0  0  0  2  1  0  0  3  2  0 13]\n",
            " [ 1  0  0  0  3  0  0  5  0  0  0  0  3  1]\n",
            " [ 1  1  0  0  0  0  0  1  7  1  3  0  0  1]\n",
            " [ 0  0  1  0  0  0  0  0  0  6  0  0  0  5]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  3  0  1  3]\n",
            " [ 0  0  0  1  3  0  0  0  0  0  2  5  2  2]\n",
            " [ 2  0  0  0  0  0  0  0  1  0  1  1 13  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hWSIC4xzF4z"
      },
      "source": [
        "# 6 Algoritmo DL "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEHTtHX9zF4z"
      },
      "source": [
        "# Escalamiento del vector de características "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jEYHjeSzF4z"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
        "feature_vectors = scaler.transform(feature_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmdEuN_zzF40"
      },
      "source": [
        "# Segmentación de los datos para entrenamiento y pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfZt9MUezF40"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "validation_size = 0.2\n",
        "seed = 0\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(feature_vectors, correct_FlowPattern_labels, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeWSSekqzF40"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhow6KLezF40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0efccc8a-5840-4a10-9a79-a5eec563cb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP = MLPClassifier(solver='lbfgs', alpha=.3,\n",
        "                    hidden_layer_sizes=(1000),\n",
        "                   )\n",
        "MLP.fit(X_train,Y_train)\n",
        "predictions = MLP.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olbcCjqNzF40",
        "outputId": "871215d4-5351-44b2-dc58-166a64c0de65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flow Pattern classification accuracy = 0.592516\n",
            "Accuracy: 0.5925155925155925\n",
            "F1 score: 0.5911243785988882\n",
            "Recall: 0.5925155925155925\n",
            "Precision: 0.5933717323924461\n",
            "\n",
            " clasification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          0       0.50      0.54      0.52       151\n",
            "          1       0.43      0.48      0.46       132\n",
            "         10       0.53      0.62      0.57        74\n",
            "         11       0.96      0.99      0.97       143\n",
            "         12       0.58      0.64      0.61       147\n",
            "         13       0.50      0.51      0.51       135\n",
            "          2       0.67      0.68      0.68       141\n",
            "          3       0.46      0.46      0.46       153\n",
            "          4       0.62      0.53      0.58       131\n",
            "          5       0.87      0.78      0.82       140\n",
            "          6       0.47      0.39      0.43       158\n",
            "          7       0.55      0.46      0.50       135\n",
            "          8       0.48      0.46      0.47       151\n",
            "          9       0.69      0.80      0.74       133\n",
            "\n",
            "avg / total       0.59      0.59      0.59      1924\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 82   9   6   1   5   4   2  24   7   0   3   1   7   0]\n",
            " [ 10  64   6   1   5   5   2  15   2   1   5   4  11   1]\n",
            " [  4   4  46   0   1   1   4   0   1   1   3   3   6   0]\n",
            " [  0   0   0 141   0   2   0   0   0   0   0   0   0   0]\n",
            " [  3   5   2   2  94  11   4   7   4   0   4   2   1   8]\n",
            " [  5   8   5   0  12  69   3   3   2   1   9   2   5  11]\n",
            " [  3   4   1   0   4   1  96   1   0   2  14   3   8   4]\n",
            " [ 22  12   5   0   5   6   3  71   9   0   2   4  13   1]\n",
            " [  7  14   2   0  10   5   2   3  70   1   5   5   7   0]\n",
            " [  2   0   7   0   0   0   7   0   1 109   3   5   2   4]\n",
            " [  5  11   1   1  13  17  10   4   3   5  61   5   5  17]\n",
            " [  9   8   0   0   7   6   6   8   5   4   8  62  10   2]\n",
            " [ 12  10   5   1   5   2   2  20   7   1   4  13  69   0]\n",
            " [  0   0   0   0   2   9   2   0   1   0   8   4   1 106]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeWsEQVrzF40"
      },
      "source": [
        "# 7. RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8OcYqa6zF40"
      },
      "source": [
        "# Escalamiento del vector de características "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myaVfJPmzF40"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
        "feature_vectors = scaler.transform(feature_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdc0aTwfzF41"
      },
      "source": [
        "# Segmentación de los datos para entrenamiento y pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SLV5Z29zF41"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "validation_size = 0.2\n",
        "seed = 0\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(feature_vectors, correct_FlowPattern_labels, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2M1vjV3zF41"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jrqaAHbzF41"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train, Y_train)\n",
        "predictions = RF.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz2bPWT5zF41",
        "outputId": "23c222ad-7417-47bc-b7c2-b749eb778be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.564356\n",
            "Accuracy: 0.5643564356435643\n",
            "F1 score: 0.5633105203349796\n",
            "Recall: 0.5643564356435643\n",
            "Precision: 0.6272977088050042\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.62      0.55        13\n",
            "           1       0.38      0.38      0.38         8\n",
            "          10       0.62      0.57      0.59        14\n",
            "          11       0.86      1.00      0.93        19\n",
            "          12       0.30      0.43      0.35        14\n",
            "          13       1.00      0.41      0.58        17\n",
            "           2       0.71      0.45      0.56        22\n",
            "           3       0.38      0.23      0.29        13\n",
            "           4       1.00      0.40      0.57        15\n",
            "           5       0.56      0.83      0.67        12\n",
            "           6       0.24      0.62      0.34         8\n",
            "           7       0.42      0.33      0.37        15\n",
            "           8       0.61      0.61      0.61        18\n",
            "           9       0.68      0.93      0.79        14\n",
            "\n",
            "    accuracy                           0.56       202\n",
            "   macro avg       0.59      0.56      0.54       202\n",
            "weighted avg       0.63      0.56      0.56       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 8  0  0  0  2  0  0  0  0  1  1  1  0  0]\n",
            " [ 0  3  0  0  0  0  0  3  0  0  0  1  0  1]\n",
            " [ 0  0  8  0  1  0  0  0  0  4  1  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  1  6  0  1  1  0  0  3  0  1  0]\n",
            " [ 0  0  1  1  3  7  0  0  0  0  1  1  0  3]\n",
            " [ 1  1  1  0  1  0 10  0  0  2  5  1  0  0]\n",
            " [ 1  1  0  0  3  0  1  3  0  0  0  1  3  0]\n",
            " [ 1  1  0  0  0  0  0  1  6  1  3  0  1  1]\n",
            " [ 0  0  1  0  0  0  0  0  0 10  0  0  0  1]\n",
            " [ 0  0  1  0  0  0  1  0  0  0  5  1  0  0]\n",
            " [ 1  1  1  1  2  0  1  0  0  0  1  5  2  0]\n",
            " [ 3  1  0  0  2  0  0  0  0  0  0  1 11  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    #'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    #'max_features': [2, 3],\n",
        "    #'min_samples_leaf': [3, 4, 5],\n",
        "    #'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "RF = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = RF, param_grid = param_grid, verbose=10)"
      ],
      "metadata": {
        "id": "PL1WijEJKJf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYvpylqJKcKf",
        "outputId": "7807b894-eaea-44da-8620-a600011b7af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV 1/5; 1/16] START max_depth=80, n_estimators=100.............................\n",
            "[CV 1/5; 1/16] END max_depth=80, n_estimators=100;, score=0.531 total time=   1.1s\n",
            "[CV 2/5; 1/16] START max_depth=80, n_estimators=100.............................\n",
            "[CV 2/5; 1/16] END max_depth=80, n_estimators=100;, score=0.534 total time=   1.0s\n",
            "[CV 3/5; 1/16] START max_depth=80, n_estimators=100.............................\n",
            "[CV 3/5; 1/16] END max_depth=80, n_estimators=100;, score=0.584 total time=   1.0s\n",
            "[CV 4/5; 1/16] START max_depth=80, n_estimators=100.............................\n",
            "[CV 4/5; 1/16] END max_depth=80, n_estimators=100;, score=0.578 total time=   1.0s\n",
            "[CV 5/5; 1/16] START max_depth=80, n_estimators=100.............................\n",
            "[CV 5/5; 1/16] END max_depth=80, n_estimators=100;, score=0.578 total time=   1.1s\n",
            "[CV 1/5; 2/16] START max_depth=80, n_estimators=200.............................\n",
            "[CV 1/5; 2/16] END max_depth=80, n_estimators=200;, score=0.512 total time=   1.5s\n",
            "[CV 2/5; 2/16] START max_depth=80, n_estimators=200.............................\n",
            "[CV 2/5; 2/16] END max_depth=80, n_estimators=200;, score=0.534 total time=   1.3s\n",
            "[CV 3/5; 2/16] START max_depth=80, n_estimators=200.............................\n",
            "[CV 3/5; 2/16] END max_depth=80, n_estimators=200;, score=0.596 total time=   1.3s\n",
            "[CV 4/5; 2/16] START max_depth=80, n_estimators=200.............................\n",
            "[CV 4/5; 2/16] END max_depth=80, n_estimators=200;, score=0.584 total time=   1.3s\n",
            "[CV 5/5; 2/16] START max_depth=80, n_estimators=200.............................\n",
            "[CV 5/5; 2/16] END max_depth=80, n_estimators=200;, score=0.609 total time=   1.3s\n",
            "[CV 1/5; 3/16] START max_depth=80, n_estimators=300.............................\n",
            "[CV 1/5; 3/16] END max_depth=80, n_estimators=300;, score=0.519 total time=   1.9s\n",
            "[CV 2/5; 3/16] START max_depth=80, n_estimators=300.............................\n",
            "[CV 2/5; 3/16] END max_depth=80, n_estimators=300;, score=0.553 total time=   1.9s\n",
            "[CV 3/5; 3/16] START max_depth=80, n_estimators=300.............................\n",
            "[CV 3/5; 3/16] END max_depth=80, n_estimators=300;, score=0.609 total time=   1.9s\n",
            "[CV 4/5; 3/16] START max_depth=80, n_estimators=300.............................\n",
            "[CV 4/5; 3/16] END max_depth=80, n_estimators=300;, score=0.584 total time=   1.9s\n",
            "[CV 5/5; 3/16] START max_depth=80, n_estimators=300.............................\n",
            "[CV 5/5; 3/16] END max_depth=80, n_estimators=300;, score=0.602 total time=   1.9s\n",
            "[CV 1/5; 4/16] START max_depth=80, n_estimators=1000............................\n",
            "[CV 1/5; 4/16] END max_depth=80, n_estimators=1000;, score=0.531 total time=   6.3s\n",
            "[CV 2/5; 4/16] START max_depth=80, n_estimators=1000............................\n",
            "[CV 2/5; 4/16] END max_depth=80, n_estimators=1000;, score=0.528 total time=  10.7s\n",
            "[CV 3/5; 4/16] START max_depth=80, n_estimators=1000............................\n",
            "[CV 3/5; 4/16] END max_depth=80, n_estimators=1000;, score=0.609 total time=   6.4s\n",
            "[CV 4/5; 4/16] START max_depth=80, n_estimators=1000............................\n",
            "[CV 4/5; 4/16] END max_depth=80, n_estimators=1000;, score=0.565 total time=   6.3s\n",
            "[CV 5/5; 4/16] START max_depth=80, n_estimators=1000............................\n",
            "[CV 5/5; 4/16] END max_depth=80, n_estimators=1000;, score=0.602 total time=   6.3s\n",
            "[CV 1/5; 5/16] START max_depth=90, n_estimators=100.............................\n",
            "[CV 1/5; 5/16] END max_depth=90, n_estimators=100;, score=0.506 total time=   0.6s\n",
            "[CV 2/5; 5/16] START max_depth=90, n_estimators=100.............................\n",
            "[CV 2/5; 5/16] END max_depth=90, n_estimators=100;, score=0.540 total time=   0.6s\n",
            "[CV 3/5; 5/16] START max_depth=90, n_estimators=100.............................\n",
            "[CV 3/5; 5/16] END max_depth=90, n_estimators=100;, score=0.584 total time=   0.6s\n",
            "[CV 4/5; 5/16] START max_depth=90, n_estimators=100.............................\n",
            "[CV 4/5; 5/16] END max_depth=90, n_estimators=100;, score=0.565 total time=   0.6s\n",
            "[CV 5/5; 5/16] START max_depth=90, n_estimators=100.............................\n",
            "[CV 5/5; 5/16] END max_depth=90, n_estimators=100;, score=0.584 total time=   0.6s\n",
            "[CV 1/5; 6/16] START max_depth=90, n_estimators=200.............................\n",
            "[CV 1/5; 6/16] END max_depth=90, n_estimators=200;, score=0.512 total time=   1.3s\n",
            "[CV 2/5; 6/16] START max_depth=90, n_estimators=200.............................\n",
            "[CV 2/5; 6/16] END max_depth=90, n_estimators=200;, score=0.534 total time=   1.3s\n",
            "[CV 3/5; 6/16] START max_depth=90, n_estimators=200.............................\n",
            "[CV 3/5; 6/16] END max_depth=90, n_estimators=200;, score=0.590 total time=   1.3s\n",
            "[CV 4/5; 6/16] START max_depth=90, n_estimators=200.............................\n",
            "[CV 4/5; 6/16] END max_depth=90, n_estimators=200;, score=0.571 total time=   1.3s\n",
            "[CV 5/5; 6/16] START max_depth=90, n_estimators=200.............................\n",
            "[CV 5/5; 6/16] END max_depth=90, n_estimators=200;, score=0.602 total time=   1.3s\n",
            "[CV 1/5; 7/16] START max_depth=90, n_estimators=300.............................\n",
            "[CV 1/5; 7/16] END max_depth=90, n_estimators=300;, score=0.531 total time=   1.9s\n",
            "[CV 2/5; 7/16] START max_depth=90, n_estimators=300.............................\n",
            "[CV 2/5; 7/16] END max_depth=90, n_estimators=300;, score=0.540 total time=   1.9s\n",
            "[CV 3/5; 7/16] START max_depth=90, n_estimators=300.............................\n",
            "[CV 3/5; 7/16] END max_depth=90, n_estimators=300;, score=0.596 total time=   1.9s\n",
            "[CV 4/5; 7/16] START max_depth=90, n_estimators=300.............................\n",
            "[CV 4/5; 7/16] END max_depth=90, n_estimators=300;, score=0.584 total time=   1.9s\n",
            "[CV 5/5; 7/16] START max_depth=90, n_estimators=300.............................\n",
            "[CV 5/5; 7/16] END max_depth=90, n_estimators=300;, score=0.571 total time=   1.9s\n",
            "[CV 1/5; 8/16] START max_depth=90, n_estimators=1000............................\n",
            "[CV 1/5; 8/16] END max_depth=90, n_estimators=1000;, score=0.537 total time=   6.3s\n",
            "[CV 2/5; 8/16] START max_depth=90, n_estimators=1000............................\n",
            "[CV 2/5; 8/16] END max_depth=90, n_estimators=1000;, score=0.547 total time=   6.4s\n",
            "[CV 3/5; 8/16] START max_depth=90, n_estimators=1000............................\n",
            "[CV 3/5; 8/16] END max_depth=90, n_estimators=1000;, score=0.609 total time=   6.7s\n",
            "[CV 4/5; 8/16] START max_depth=90, n_estimators=1000............................\n",
            "[CV 4/5; 8/16] END max_depth=90, n_estimators=1000;, score=0.584 total time=   7.0s\n",
            "[CV 5/5; 8/16] START max_depth=90, n_estimators=1000............................\n",
            "[CV 5/5; 8/16] END max_depth=90, n_estimators=1000;, score=0.602 total time=   6.7s\n",
            "[CV 1/5; 9/16] START max_depth=100, n_estimators=100............................\n",
            "[CV 1/5; 9/16] END max_depth=100, n_estimators=100;, score=0.549 total time=   0.6s\n",
            "[CV 2/5; 9/16] START max_depth=100, n_estimators=100............................\n",
            "[CV 2/5; 9/16] END max_depth=100, n_estimators=100;, score=0.509 total time=   0.6s\n",
            "[CV 3/5; 9/16] START max_depth=100, n_estimators=100............................\n",
            "[CV 3/5; 9/16] END max_depth=100, n_estimators=100;, score=0.571 total time=   0.7s\n",
            "[CV 4/5; 9/16] START max_depth=100, n_estimators=100............................\n",
            "[CV 4/5; 9/16] END max_depth=100, n_estimators=100;, score=0.571 total time=   0.6s\n",
            "[CV 5/5; 9/16] START max_depth=100, n_estimators=100............................\n",
            "[CV 5/5; 9/16] END max_depth=100, n_estimators=100;, score=0.584 total time=   0.7s\n",
            "[CV 1/5; 10/16] START max_depth=100, n_estimators=200...........................\n",
            "[CV 1/5; 10/16] END max_depth=100, n_estimators=200;, score=0.525 total time=   1.3s\n",
            "[CV 2/5; 10/16] START max_depth=100, n_estimators=200...........................\n",
            "[CV 2/5; 10/16] END max_depth=100, n_estimators=200;, score=0.540 total time=   1.3s\n",
            "[CV 3/5; 10/16] START max_depth=100, n_estimators=200...........................\n",
            "[CV 3/5; 10/16] END max_depth=100, n_estimators=200;, score=0.609 total time=   1.3s\n",
            "[CV 4/5; 10/16] START max_depth=100, n_estimators=200...........................\n",
            "[CV 4/5; 10/16] END max_depth=100, n_estimators=200;, score=0.584 total time=   1.3s\n",
            "[CV 5/5; 10/16] START max_depth=100, n_estimators=200...........................\n",
            "[CV 5/5; 10/16] END max_depth=100, n_estimators=200;, score=0.590 total time=   1.3s\n",
            "[CV 1/5; 11/16] START max_depth=100, n_estimators=300...........................\n",
            "[CV 1/5; 11/16] END max_depth=100, n_estimators=300;, score=0.519 total time=   1.9s\n",
            "[CV 2/5; 11/16] START max_depth=100, n_estimators=300...........................\n",
            "[CV 2/5; 11/16] END max_depth=100, n_estimators=300;, score=0.553 total time=   1.9s\n",
            "[CV 3/5; 11/16] START max_depth=100, n_estimators=300...........................\n",
            "[CV 3/5; 11/16] END max_depth=100, n_estimators=300;, score=0.602 total time=   1.9s\n",
            "[CV 4/5; 11/16] START max_depth=100, n_estimators=300...........................\n",
            "[CV 4/5; 11/16] END max_depth=100, n_estimators=300;, score=0.565 total time=   1.9s\n",
            "[CV 5/5; 11/16] START max_depth=100, n_estimators=300...........................\n",
            "[CV 5/5; 11/16] END max_depth=100, n_estimators=300;, score=0.578 total time=   1.9s\n",
            "[CV 1/5; 12/16] START max_depth=100, n_estimators=1000..........................\n",
            "[CV 1/5; 12/16] END max_depth=100, n_estimators=1000;, score=0.537 total time=   6.3s\n",
            "[CV 2/5; 12/16] START max_depth=100, n_estimators=1000..........................\n",
            "[CV 2/5; 12/16] END max_depth=100, n_estimators=1000;, score=0.540 total time=   6.4s\n",
            "[CV 3/5; 12/16] START max_depth=100, n_estimators=1000..........................\n",
            "[CV 3/5; 12/16] END max_depth=100, n_estimators=1000;, score=0.602 total time=   6.4s\n",
            "[CV 4/5; 12/16] START max_depth=100, n_estimators=1000..........................\n",
            "[CV 4/5; 12/16] END max_depth=100, n_estimators=1000;, score=0.584 total time=   6.3s\n",
            "[CV 5/5; 12/16] START max_depth=100, n_estimators=1000..........................\n",
            "[CV 5/5; 12/16] END max_depth=100, n_estimators=1000;, score=0.609 total time=   6.3s\n",
            "[CV 1/5; 13/16] START max_depth=110, n_estimators=100...........................\n",
            "[CV 1/5; 13/16] END max_depth=110, n_estimators=100;, score=0.525 total time=   0.6s\n",
            "[CV 2/5; 13/16] START max_depth=110, n_estimators=100...........................\n",
            "[CV 2/5; 13/16] END max_depth=110, n_estimators=100;, score=0.547 total time=   0.7s\n",
            "[CV 3/5; 13/16] START max_depth=110, n_estimators=100...........................\n",
            "[CV 3/5; 13/16] END max_depth=110, n_estimators=100;, score=0.578 total time=   0.6s\n",
            "[CV 4/5; 13/16] START max_depth=110, n_estimators=100...........................\n",
            "[CV 4/5; 13/16] END max_depth=110, n_estimators=100;, score=0.540 total time=   0.6s\n",
            "[CV 5/5; 13/16] START max_depth=110, n_estimators=100...........................\n",
            "[CV 5/5; 13/16] END max_depth=110, n_estimators=100;, score=0.565 total time=   0.6s\n",
            "[CV 1/5; 14/16] START max_depth=110, n_estimators=200...........................\n",
            "[CV 1/5; 14/16] END max_depth=110, n_estimators=200;, score=0.512 total time=   1.3s\n",
            "[CV 2/5; 14/16] START max_depth=110, n_estimators=200...........................\n",
            "[CV 2/5; 14/16] END max_depth=110, n_estimators=200;, score=0.547 total time=   1.3s\n",
            "[CV 3/5; 14/16] START max_depth=110, n_estimators=200...........................\n",
            "[CV 3/5; 14/16] END max_depth=110, n_estimators=200;, score=0.609 total time=   1.3s\n",
            "[CV 4/5; 14/16] START max_depth=110, n_estimators=200...........................\n",
            "[CV 4/5; 14/16] END max_depth=110, n_estimators=200;, score=0.590 total time=   1.3s\n",
            "[CV 5/5; 14/16] START max_depth=110, n_estimators=200...........................\n",
            "[CV 5/5; 14/16] END max_depth=110, n_estimators=200;, score=0.590 total time=   1.3s\n",
            "[CV 1/5; 15/16] START max_depth=110, n_estimators=300...........................\n",
            "[CV 1/5; 15/16] END max_depth=110, n_estimators=300;, score=0.525 total time=   1.9s\n",
            "[CV 2/5; 15/16] START max_depth=110, n_estimators=300...........................\n",
            "[CV 2/5; 15/16] END max_depth=110, n_estimators=300;, score=0.534 total time=   1.9s\n",
            "[CV 3/5; 15/16] START max_depth=110, n_estimators=300...........................\n",
            "[CV 3/5; 15/16] END max_depth=110, n_estimators=300;, score=0.615 total time=   1.9s\n",
            "[CV 4/5; 15/16] START max_depth=110, n_estimators=300...........................\n",
            "[CV 4/5; 15/16] END max_depth=110, n_estimators=300;, score=0.584 total time=   1.9s\n",
            "[CV 5/5; 15/16] START max_depth=110, n_estimators=300...........................\n",
            "[CV 5/5; 15/16] END max_depth=110, n_estimators=300;, score=0.578 total time=   1.9s\n",
            "[CV 1/5; 16/16] START max_depth=110, n_estimators=1000..........................\n",
            "[CV 1/5; 16/16] END max_depth=110, n_estimators=1000;, score=0.525 total time=   6.3s\n",
            "[CV 2/5; 16/16] START max_depth=110, n_estimators=1000..........................\n",
            "[CV 2/5; 16/16] END max_depth=110, n_estimators=1000;, score=0.534 total time=   6.4s\n",
            "[CV 3/5; 16/16] START max_depth=110, n_estimators=1000..........................\n",
            "[CV 3/5; 16/16] END max_depth=110, n_estimators=1000;, score=0.621 total time=   6.4s\n",
            "[CV 4/5; 16/16] START max_depth=110, n_estimators=1000..........................\n",
            "[CV 4/5; 16/16] END max_depth=110, n_estimators=1000;, score=0.578 total time=   6.3s\n",
            "[CV 5/5; 16/16] START max_depth=110, n_estimators=1000..........................\n",
            "[CV 5/5; 16/16] END max_depth=110, n_estimators=1000;, score=0.578 total time=   6.4s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=RandomForestClassifier(),\n",
              "             param_grid={'max_depth': [80, 90, 100, 110],\n",
              "                         'n_estimators': [100, 200, 300, 1000]},\n",
              "             verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_search.best_params_,grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhbxC1HpNwdc",
        "outputId": "e15c8b9a-38e5-4908-8594-948bb3b0af8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 90, 'n_estimators': 1000} 0.5757303887738671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = grid_search.predict(X_validation)"
      ],
      "metadata": {
        "id": "RdSlM8FsOO-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados(Y_validation, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BisowWWOHHj",
        "outputId": "ed351245-3e1e-432a-9c67-b7c3b268351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.599010\n",
            "Accuracy: 0.599009900990099\n",
            "F1 score: 0.5995264455240431\n",
            "Recall: 0.599009900990099\n",
            "Precision: 0.6559400525941871\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.69      0.60        13\n",
            "           1       0.50      0.50      0.50         8\n",
            "          10       0.67      0.57      0.62        14\n",
            "          11       0.90      1.00      0.95        19\n",
            "          12       0.36      0.57      0.44        14\n",
            "          13       0.86      0.35      0.50        17\n",
            "           2       0.71      0.55      0.62        22\n",
            "           3       0.50      0.31      0.38        13\n",
            "           4       0.88      0.47      0.61        15\n",
            "           5       0.60      0.75      0.67        12\n",
            "           6       0.22      0.62      0.32         8\n",
            "           7       0.62      0.33      0.43        15\n",
            "           8       0.65      0.61      0.63        18\n",
            "           9       0.74      1.00      0.85        14\n",
            "\n",
            "    accuracy                           0.60       202\n",
            "   macro avg       0.62      0.59      0.58       202\n",
            "weighted avg       0.66      0.60      0.60       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 9  1  0  0  1  0  0  0  0  1  1  0  0  0]\n",
            " [ 1  4  0  0  0  0  1  2  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  1  0  1  0  0  2  2  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  8  0  1  1  0  0  3  0  1  0]\n",
            " [ 0  1  1  1  4  6  0  0  0  0  1  0  0  3]\n",
            " [ 0  0  1  0  2  0 12  0  0  2  4  1  0  0]\n",
            " [ 2  0  0  0  3  0  0  4  0  0  1  1  2  0]\n",
            " [ 1  0  0  0  0  0  0  1  7  1  3  0  1  1]\n",
            " [ 0  0  1  0  0  0  0  0  0  9  1  0  0  1]\n",
            " [ 0  0  0  0  0  0  1  0  1  0  5  1  0  0]\n",
            " [ 1  0  0  1  2  1  1  0  0  0  2  5  2  0]\n",
            " [ 3  2  1  0  1  0  0  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "908dB_-JzF41"
      },
      "source": [
        "# 8. Desicion Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pPrTIp2zF41"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(X_train, Y_train)\n",
        "predictions =DT.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTCm-YyqzF42",
        "outputId": "5390d029-ab23-44ee-e91a-b54adeccd7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flow Pattern classification accuracy = 0.465347\n",
            "Accuracy: 0.46534653465346537\n",
            "F1 score: 0.47417438835003173\n",
            "Recall: 0.46534653465346537\n",
            "Precision: 0.506709275484756\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.54      0.47        13\n",
            "           1       0.06      0.12      0.08         8\n",
            "          10       0.38      0.36      0.37        14\n",
            "          11       0.83      0.79      0.81        19\n",
            "          12       0.35      0.43      0.39        14\n",
            "          13       0.50      0.35      0.41        17\n",
            "           2       0.81      0.59      0.68        22\n",
            "           3       0.25      0.31      0.28        13\n",
            "           4       0.50      0.20      0.29        15\n",
            "           5       0.60      0.75      0.67        12\n",
            "           6       0.21      0.38      0.27         8\n",
            "           7       0.40      0.27      0.32        15\n",
            "           8       0.50      0.44      0.47        18\n",
            "           9       0.67      0.71      0.69        14\n",
            "\n",
            "    accuracy                           0.47       202\n",
            "   macro avg       0.46      0.45      0.44       202\n",
            "weighted avg       0.51      0.47      0.47       202\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[ 7  1  1  0  1  0  0  0  1  0  1  1  0  0]\n",
            " [ 2  1  1  0  0  0  0  1  0  0  2  0  1  0]\n",
            " [ 1  2  5  0  0  1  0  1  0  0  1  1  1  1]\n",
            " [ 0  2  0 15  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  3  0  1  6  1  0  2  0  0  0  1  0  0]\n",
            " [ 1  0  1  1  2  6  0  0  1  1  1  0  0  3]\n",
            " [ 2  0  0  0  2  0 13  0  0  2  2  1  0  0]\n",
            " [ 0  1  1  0  2  0  0  4  1  0  0  1  3  0]\n",
            " [ 1  4  1  0  1  0  0  3  3  1  1  0  0  0]\n",
            " [ 0  0  1  0  1  0  0  0  0  9  0  0  0  1]\n",
            " [ 1  0  0  0  0  1  1  0  0  1  3  1  0  0]\n",
            " [ 0  0  1  1  2  1  1  2  0  0  1  4  2  0]\n",
            " [ 2  3  1  0  0  0  0  3  0  1  0  0  8  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  2  0  1 10]]\n"
          ]
        }
      ],
      "source": [
        "resultados(Y_validation,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio\n",
        "\n",
        "Realizar optimización de parametros sobre DT"
      ],
      "metadata": {
        "id": "D2bR7FTlOpLa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NM9lwPwzF4t"
      },
      "source": [
        "# Evaluación inicial del compartamiento de cada uno de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sSdUHsGzF4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9efcdd-115c-445b-bb25-e9c67a88be95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: 0.445463 (0.040312)\n",
            "LDA: 0.124012 (0.036993)\n",
            "KNN: 0.114120 (0.020512)\n",
            "NB: 0.275386 (0.027040)\n",
            "SVM: 0.404429 (0.041114)\n",
            "MLP: 0.187346 (0.017884)\n",
            "RF: 0.428056 (0.040568)\n",
            "DT: 0.346265 (0.046600)\n"
          ]
        }
      ],
      "source": [
        "seed = 42\n",
        "scoring = 'accuracy'\n",
        "\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "models.append(('MLP', MLPClassifier()))\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('DT', DecisionTreeClassifier()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)\n",
        "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# We can also create a plot of the model evaluation results and compare the spread and the mean accuracy of each model. There is a population of accuracy measures for each algorithm because each algorithm was evaluated 10 times (10 fold cross validation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwLiIfLKzF4u",
        "outputId": "33a9ee3e-0171-478a-9d2a-9404a40718e3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare Algorithms Accuracy\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Deep Learning"
      ],
      "metadata": {
        "id": "qclyXXxtA2jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "wGHE3v5rBKac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_labels_train = keras.utils.to_categorical(Y_train, num_classes=14)\n",
        "one_hot_labels_validation = keras.utils.to_categorical(Y_validation, num_classes=14)"
      ],
      "metadata": {
        "id": "va49EOZpAzJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_labels_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHwf7yI5BFw1",
        "outputId": "8d466cd4-8bfe-4a78-fd2e-dda6f3e11c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu',))\n",
        "model.add(Dense(200, activation='relu',))\n",
        "#model.add(Dense(200, activation='relu',))\n",
        "model.add(Dense(64, activation='relu',))\n",
        "#model.add(Dense(100, activation='relu',))\n",
        "#model.add(Dense(8000, activation='relu',))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(1000, activation='tanh',))\n",
        "#model.add(Dense(100, activation='relu',))\n",
        "model.add(Dense(14, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mse','mae','mape'])  \n",
        "\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "#one_hot_labels_train = keras.utils.to_categorical(Y_train, num_classes=14)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "history=model.fit(X_train, one_hot_labels_train, epochs=50, batch_size=100)\n",
        "#plt.subplot(2,2,1)\n",
        "plt.plot(history.history['acc'])\n",
        "#plt.subplot(2,2,2)\n",
        "#plt.plot(history.history['mse'])\n",
        "#plt.subplot(2,2,3)\n",
        "#plt.plot(history.history['mae'])\n",
        "#plt.subplot(2,2,4)\n",
        "#plt.plot(history.history['mape'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2pvW0jrvBz7Q",
        "outputId": "b3eb3cf6-f62a-4a66-915c-95571e8ac818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 200)               25800     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                12864     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 14)                910       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,358\n",
            "Trainable params: 54,358\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 5ms/step - loss: 40.9320 - acc: 0.1452 - mse: 0.1168 - mae: 0.1223 - mape: 61165304.0000\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0260 - acc: 0.2779 - mse: 0.0921 - mae: 0.1036 - mape: 51793044.0000\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6704 - acc: 0.3002 - mse: 0.0808 - mae: 0.1012 - mape: 50584136.0000\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4550 - acc: 0.3164 - mse: 0.0675 - mae: 0.1016 - mape: 50805788.0000\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8805 - acc: 0.3511 - mse: 0.0598 - mae: 0.0996 - mape: 49794868.0000\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4316 - acc: 0.3660 - mse: 0.0563 - mae: 0.0992 - mape: 49578040.0000\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.9989 - acc: 0.4020 - mse: 0.0511 - mae: 0.0961 - mape: 48038416.0000\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.8075 - acc: 0.4119 - mse: 0.0484 - mae: 0.0936 - mape: 46781860.0000\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6846 - acc: 0.4491 - mse: 0.0452 - mae: 0.0893 - mape: 44651080.0000\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6081 - acc: 0.4479 - mse: 0.0442 - mae: 0.0878 - mape: 43913700.0000\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.5333 - acc: 0.4864 - mse: 0.0423 - mae: 0.0853 - mape: 42656528.0000\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4749 - acc: 0.5062 - mse: 0.0409 - mae: 0.0830 - mape: 41524904.0000\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4557 - acc: 0.5000 - mse: 0.0414 - mae: 0.0835 - mape: 41734860.0000\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4005 - acc: 0.5199 - mse: 0.0395 - mae: 0.0796 - mape: 39779360.0000\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3504 - acc: 0.5397 - mse: 0.0388 - mae: 0.0789 - mape: 39441908.0000\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3304 - acc: 0.5596 - mse: 0.0378 - mae: 0.0766 - mape: 38307220.0000\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2859 - acc: 0.5447 - mse: 0.0377 - mae: 0.0764 - mape: 38175468.0000\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2430 - acc: 0.5558 - mse: 0.0361 - mae: 0.0730 - mape: 36522824.0000\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1695 - acc: 0.5806 - mse: 0.0346 - mae: 0.0713 - mape: 35643188.0000\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2364 - acc: 0.5484 - mse: 0.0376 - mae: 0.0754 - mape: 37692132.0000\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1833 - acc: 0.5782 - mse: 0.0350 - mae: 0.0718 - mape: 35876896.0000\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1546 - acc: 0.5906 - mse: 0.0338 - mae: 0.0685 - mape: 34257080.0000\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1237 - acc: 0.5782 - mse: 0.0337 - mae: 0.0685 - mape: 34271880.0000\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0569 - acc: 0.6166 - mse: 0.0319 - mae: 0.0660 - mape: 32979206.0000\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0350 - acc: 0.6179 - mse: 0.0312 - mae: 0.0631 - mape: 31555200.0000\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0082 - acc: 0.6203 - mse: 0.0306 - mae: 0.0614 - mape: 30720148.0000\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9704 - acc: 0.6526 - mse: 0.0292 - mae: 0.0613 - mape: 30659582.0000\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9058 - acc: 0.6712 - mse: 0.0277 - mae: 0.0575 - mape: 28770952.0000\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8585 - acc: 0.6725 - mse: 0.0264 - mae: 0.0559 - mape: 27969596.0000\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8307 - acc: 0.6911 - mse: 0.0256 - mae: 0.0550 - mape: 27523586.0000\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7999 - acc: 0.7022 - mse: 0.0247 - mae: 0.0527 - mape: 26364148.0000\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7770 - acc: 0.7035 - mse: 0.0240 - mae: 0.0517 - mape: 25873108.0000\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7462 - acc: 0.7171 - mse: 0.0231 - mae: 0.0502 - mape: 25112382.0000\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7467 - acc: 0.7097 - mse: 0.0232 - mae: 0.0511 - mape: 25546604.0000\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7309 - acc: 0.7171 - mse: 0.0230 - mae: 0.0489 - mape: 24461052.0000\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6936 - acc: 0.7407 - mse: 0.0217 - mae: 0.0480 - mape: 24008188.0000\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6712 - acc: 0.7506 - mse: 0.0209 - mae: 0.0459 - mape: 22956646.0000\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6375 - acc: 0.7593 - mse: 0.0199 - mae: 0.0442 - mape: 22104606.0000\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6288 - acc: 0.7593 - mse: 0.0197 - mae: 0.0432 - mape: 21623638.0000\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6185 - acc: 0.7717 - mse: 0.0192 - mae: 0.0426 - mape: 21318290.0000\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5897 - acc: 0.7767 - mse: 0.0184 - mae: 0.0413 - mape: 20625838.0000\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5657 - acc: 0.7804 - mse: 0.0177 - mae: 0.0400 - mape: 19991820.0000\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5509 - acc: 0.7928 - mse: 0.0172 - mae: 0.0391 - mape: 19573264.0000\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5370 - acc: 0.7928 - mse: 0.0168 - mae: 0.0384 - mape: 19200110.0000\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5290 - acc: 0.8002 - mse: 0.0165 - mae: 0.0376 - mape: 18775778.0000\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5442 - acc: 0.7928 - mse: 0.0173 - mae: 0.0385 - mape: 19240050.0000\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5256 - acc: 0.8065 - mse: 0.0167 - mae: 0.0378 - mape: 18891488.0000\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5524 - acc: 0.8040 - mse: 0.0171 - mae: 0.0377 - mape: 18869740.0000\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5776 - acc: 0.7940 - mse: 0.0180 - mae: 0.0386 - mape: 19280002.0000\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5443 - acc: 0.8089 - mse: 0.0166 - mae: 0.0370 - mape: 18496558.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_validation, one_hot_labels_validation, batch_size=64)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQpofR7ZB5by",
        "outputId": "097d375d-8bf3-4346-b794-e5082a76c901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step - loss: 6.7164 - acc: 0.3317 - mse: 0.0739 - mae: 0.0984 - mape: 49190184.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.716403484344482,\n",
              " 0.3316831588745117,\n",
              " 0.07389137148857117,\n",
              " 0.09838036447763443,\n",
              " 49190184.0]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Auto Machine Learning "
      ],
      "metadata": {
        "id": "Cminz2EJXaTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First install package from terminal:\n",
        "# pip install -U pip\n",
        "# pip install -U setuptools wheel\n",
        "# pip install autogluon  # autogluon==0.4.0\n",
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
        "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH-IXapWVKm7",
        "outputId": "6546d806-3887-488b-9867-8fcb01800505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc9VccUfc4w_",
        "outputId": "027ec439-318d-4545-c1b9-105ba3880c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age   workclass  fnlwgt   education  education-num       marital-status  \\\n",
            "0   25     Private  178478   Bachelors             13        Never-married   \n",
            "1   23   State-gov   61743     5th-6th              3        Never-married   \n",
            "2   46     Private  376789     HS-grad              9        Never-married   \n",
            "3   55           ?  200235     HS-grad              9   Married-civ-spouse   \n",
            "4   36     Private  224541     7th-8th              4   Married-civ-spouse   \n",
            "\n",
            "           occupation    relationship    race      sex  capital-gain  \\\n",
            "0        Tech-support       Own-child   White   Female             0   \n",
            "1    Transport-moving   Not-in-family   White     Male             0   \n",
            "2       Other-service   Not-in-family   White     Male             0   \n",
            "3                   ?         Husband   White     Male             0   \n",
            "4   Handlers-cleaners         Husband   White     Male             0   \n",
            "\n",
            "   capital-loss  hours-per-week  native-country   class  \n",
            "0             0              40   United-States   <=50K  \n",
            "1             0              35   United-States   <=50K  \n",
            "2             0              15   United-States   <=50K  \n",
            "3             0              50   United-States    >50K  \n",
            "4             0              40     El-Salvador   <=50K  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTtLu5PEc72i",
        "outputId": "03ee4e2e-2cdd-49a7-a987-27f3ffd417ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
            "count  39073.000000  3.907300e+04   39073.000000  39073.000000  39073.000000   \n",
            "mean      38.616743  1.899605e+05      10.078085   1117.146802     88.002866   \n",
            "std       13.718529  1.055563e+05       2.569742   7701.078403    403.732117   \n",
            "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
            "25%       28.000000  1.177740e+05       9.000000      0.000000      0.000000   \n",
            "50%       37.000000  1.783410e+05      10.000000      0.000000      0.000000   \n",
            "75%       48.000000  2.383420e+05      12.000000      0.000000      0.000000   \n",
            "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
            "\n",
            "       hours-per-week  \n",
            "count    39073.000000  \n",
            "mean        40.407673  \n",
            "std         12.362809  \n",
            "min          1.000000  \n",
            "25%         40.000000  \n",
            "50%         40.000000  \n",
            "75%         45.000000  \n",
            "max         99.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label='class').fit(train_data, time_limit=120)  # Fit models for 120s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_jk33o3cvQm",
        "outputId": "77547a7a-b1dc-4a9e-8a4e-091dd7f4bb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220408_043438/\"\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220408_043438/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    39073\n",
            "Train Data Columns: 14\n",
            "Label Column: class\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' <=50K', ' >50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11253.43 MB\n",
            "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.4s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.5s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.0639828014229775, Train Rows: 36573, Val Rows: 2500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 119.5s of the 119.49s of remaining time.\n",
            "\t0.7752\t = Validation score   (accuracy)\n",
            "\t0.11s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ... Training model for up to 119.25s of the 119.25s of remaining time.\n",
            "\t0.766\t = Validation score   (accuracy)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 119.01s of the 119.01s of remaining time.\n",
            "\t0.8792\t = Validation score   (accuracy)\n",
            "\t2.77s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 116.09s of the 116.09s of remaining time.\n",
            "\t0.8824\t = Validation score   (accuracy)\n",
            "\t1.95s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 114.05s of the 114.05s of remaining time.\n",
            "\t0.864\t = Validation score   (accuracy)\n",
            "\t9.97s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 102.77s of the 102.77s of remaining time.\n",
            "\t0.8608\t = Validation score   (accuracy)\n",
            "\t17.41s\t = Training   runtime\n",
            "\t0.52s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 83.74s of the 83.73s of remaining time.\n",
            "\t0.8836\t = Validation score   (accuracy)\n",
            "\t36.04s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 47.67s of the 47.66s of remaining time.\n",
            "\t0.8496\t = Validation score   (accuracy)\n",
            "\t6.36s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 39.11s of the 39.11s of remaining time.\n",
            "\t0.8496\t = Validation score   (accuracy)\n",
            "\t6.97s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 30.1s of the 30.1s of remaining time.\n",
            "\t0.8628\t = Validation score   (accuracy)\n",
            "\t29.39s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 0.62s of the 0.62s of remaining time.\n",
            "\t0.872\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.5s of the -4.21s of remaining time.\n",
            "\t0.8864\t = Validation score   (accuracy)\n",
            "\t1.35s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 125.64s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220408_043438/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = predictor.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwfZ03kfdD1h",
        "outputId": "b1c8b4d3-7926-4eff-fff1-9eac358b350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: accuracy on test data: 0.8767529941652165\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.8767529941652165,\n",
            "    \"balanced_accuracy\": 0.795126057397256,\n",
            "    \"mcc\": 0.6406203577595788,\n",
            "    \"roc_auc\": 0.9297192332441957,\n",
            "    \"f1\": 0.7112709832134292,\n",
            "    \"precision\": 0.800755939524838,\n",
            "    \"recall\": 0.6397756686798964\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard = predictor.leaderboard(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Loc8dncvrv",
        "outputId": "2af3c6b6-3322-4ad8-e75a-b549bb076bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2    0.876753     0.8864        1.392325       0.443720  71.705051                 0.059249                0.005404           1.351176            2       True         12\n",
            "1              CatBoost    0.875627     0.8836        0.039340       0.025799  36.035641                 0.039340                0.025799          36.035641            1       True          7\n",
            "2              LightGBM    0.873477     0.8824        0.370032       0.053497   1.951005                 0.370032                0.053497           1.951005            1       True          4\n",
            "3            LightGBMXT    0.871430     0.8792        0.280367       0.075792   2.768765                 0.280367                0.075792           2.768765            1       True          3\n",
            "4               XGBoost    0.868871     0.8720        0.066423       0.027042   0.668326                 0.066423                0.027042           0.668326            1       True         11\n",
            "5       NeuralNetFastAI    0.858839     0.8628        0.194088       0.057627  29.385520                 0.194088                0.057627          29.385520            1       True         10\n",
            "6      RandomForestGini    0.858532     0.8640        0.880570       0.312669   9.969909                 0.880570                0.312669           9.969909            1       True          5\n",
            "7      RandomForestEntr    0.858225     0.8608        1.036614       0.520466  17.410235                 1.036614                0.520466          17.410235            1       True          6\n",
            "8        ExtraTreesGini    0.851264     0.8496        1.348474       0.314304   6.362925                 1.348474                0.314304           6.362925            1       True          8\n",
            "9        ExtraTreesEntr    0.851059     0.8496        1.320891       0.313502   6.974835                 1.320891                0.313502           6.974835            1       True          9\n",
            "10       KNeighborsUnif    0.773467     0.7752        0.213496       0.115768   0.110614                 0.213496                0.115768           0.110614            1       True          1\n",
            "11       KNeighborsDist    0.762514     0.7660        0.235752       0.109834   0.102330                 0.235752                0.109834           0.102330            1       True          2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPdD20tGbDhT",
        "outputId": "2b6ff028-8e35-4905-a7fa-f2d82d35fed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2     0.8864       0.443720  71.705051                0.005404           1.351176            2       True         12\n",
            "1              CatBoost     0.8836       0.025799  36.035641                0.025799          36.035641            1       True          7\n",
            "2              LightGBM     0.8824       0.053497   1.951005                0.053497           1.951005            1       True          4\n",
            "3            LightGBMXT     0.8792       0.075792   2.768765                0.075792           2.768765            1       True          3\n",
            "4               XGBoost     0.8720       0.027042   0.668326                0.027042           0.668326            1       True         11\n",
            "5      RandomForestGini     0.8640       0.312669   9.969909                0.312669           9.969909            1       True          5\n",
            "6       NeuralNetFastAI     0.8628       0.057627  29.385520                0.057627          29.385520            1       True         10\n",
            "7      RandomForestEntr     0.8608       0.520466  17.410235                0.520466          17.410235            1       True          6\n",
            "8        ExtraTreesEntr     0.8496       0.313502   6.974835                0.313502           6.974835            1       True          9\n",
            "9        ExtraTreesGini     0.8496       0.314304   6.362925                0.314304           6.362925            1       True          8\n",
            "10       KNeighborsUnif     0.7752       0.115768   0.110614                0.115768           0.110614            1       True          1\n",
            "11       KNeighborsDist     0.7660       0.109834   0.102330                0.109834           0.102330            1       True          2\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'KNNModel', 'CatBoostModel', 'RFModel', 'LGBModel', 'XGBoostModel', 'XTModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "('int', ['bool']) : 1 | ['sex']\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20220408_043438/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif': 'KNNModel',\n",
              "  'KNeighborsDist': 'KNNModel',\n",
              "  'LightGBMXT': 'LGBModel',\n",
              "  'LightGBM': 'LGBModel',\n",
              "  'RandomForestGini': 'RFModel',\n",
              "  'RandomForestEntr': 'RFModel',\n",
              "  'CatBoost': 'CatBoostModel',\n",
              "  'ExtraTreesGini': 'XTModel',\n",
              "  'ExtraTreesEntr': 'XTModel',\n",
              "  'NeuralNetFastAI': 'NNFastAiTabularModel',\n",
              "  'XGBoost': 'XGBoostModel',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif': 0.7752,\n",
              "  'KNeighborsDist': 0.766,\n",
              "  'LightGBMXT': 0.8792,\n",
              "  'LightGBM': 0.8824,\n",
              "  'RandomForestGini': 0.864,\n",
              "  'RandomForestEntr': 0.8608,\n",
              "  'CatBoost': 0.8836,\n",
              "  'ExtraTreesGini': 0.8496,\n",
              "  'ExtraTreesEntr': 0.8496,\n",
              "  'NeuralNetFastAI': 0.8628,\n",
              "  'XGBoost': 0.872,\n",
              "  'WeightedEnsemble_L2': 0.8864},\n",
              " 'model_best': 'WeightedEnsemble_L2',\n",
              " 'model_paths': {'KNeighborsUnif': 'AutogluonModels/ag-20220408_043438/models/KNeighborsUnif/',\n",
              "  'KNeighborsDist': 'AutogluonModels/ag-20220408_043438/models/KNeighborsDist/',\n",
              "  'LightGBMXT': 'AutogluonModels/ag-20220408_043438/models/LightGBMXT/',\n",
              "  'LightGBM': 'AutogluonModels/ag-20220408_043438/models/LightGBM/',\n",
              "  'RandomForestGini': 'AutogluonModels/ag-20220408_043438/models/RandomForestGini/',\n",
              "  'RandomForestEntr': 'AutogluonModels/ag-20220408_043438/models/RandomForestEntr/',\n",
              "  'CatBoost': 'AutogluonModels/ag-20220408_043438/models/CatBoost/',\n",
              "  'ExtraTreesGini': 'AutogluonModels/ag-20220408_043438/models/ExtraTreesGini/',\n",
              "  'ExtraTreesEntr': 'AutogluonModels/ag-20220408_043438/models/ExtraTreesEntr/',\n",
              "  'NeuralNetFastAI': 'AutogluonModels/ag-20220408_043438/models/NeuralNetFastAI/',\n",
              "  'XGBoost': 'AutogluonModels/ag-20220408_043438/models/XGBoost/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220408_043438/models/WeightedEnsemble_L2/'},\n",
              " 'model_fit_times': {'KNeighborsUnif': 0.11061429977416992,\n",
              "  'KNeighborsDist': 0.10232996940612793,\n",
              "  'LightGBMXT': 2.7687647342681885,\n",
              "  'LightGBM': 1.951005220413208,\n",
              "  'RandomForestGini': 9.969909191131592,\n",
              "  'RandomForestEntr': 17.410235166549683,\n",
              "  'CatBoost': 36.03564119338989,\n",
              "  'ExtraTreesGini': 6.362924814224243,\n",
              "  'ExtraTreesEntr': 6.974835395812988,\n",
              "  'NeuralNetFastAI': 29.3855197429657,\n",
              "  'XGBoost': 0.6683259010314941,\n",
              "  'WeightedEnsemble_L2': 1.3511760234832764},\n",
              " 'model_pred_times': {'KNeighborsUnif': 0.1157681941986084,\n",
              "  'KNeighborsDist': 0.1098337173461914,\n",
              "  'LightGBMXT': 0.07579159736633301,\n",
              "  'LightGBM': 0.053496599197387695,\n",
              "  'RandomForestGini': 0.3126688003540039,\n",
              "  'RandomForestEntr': 0.5204658508300781,\n",
              "  'CatBoost': 0.025798797607421875,\n",
              "  'ExtraTreesGini': 0.3143038749694824,\n",
              "  'ExtraTreesEntr': 0.31350207328796387,\n",
              "  'NeuralNetFastAI': 0.05762743949890137,\n",
              "  'XGBoost': 0.027042150497436523,\n",
              "  'WeightedEnsemble_L2': 0.005403757095336914},\n",
              " 'num_bag_folds': 0,\n",
              " 'max_stack_level': 2,\n",
              " 'num_classes': 2,\n",
              " 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'},\n",
              "  'KNeighborsDist': {'weights': 'distance'},\n",
              "  'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True},\n",
              "  'LightGBM': {'learning_rate': 0.05},\n",
              "  'RandomForestGini': {'n_estimators': 300,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'gini'},\n",
              "  'RandomForestEntr': {'n_estimators': 300,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'entropy'},\n",
              "  'CatBoost': {'iterations': 10000,\n",
              "   'learning_rate': 0.05,\n",
              "   'random_seed': 0,\n",
              "   'allow_writing_files': False,\n",
              "   'eval_metric': 'Accuracy'},\n",
              "  'ExtraTreesGini': {'n_estimators': 300,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'gini'},\n",
              "  'ExtraTreesEntr': {'n_estimators': 300,\n",
              "   'n_jobs': -1,\n",
              "   'random_state': 0,\n",
              "   'bootstrap': True,\n",
              "   'criterion': 'entropy'},\n",
              "  'NeuralNetFastAI': {'layers': None,\n",
              "   'emb_drop': 0.1,\n",
              "   'ps': 0.1,\n",
              "   'bs': 'auto',\n",
              "   'lr': 0.01,\n",
              "   'epochs': 'auto',\n",
              "   'early.stopping.min_delta': 0.0001,\n",
              "   'early.stopping.patience': 20,\n",
              "   'smoothing': 0.0},\n",
              "  'XGBoost': {'n_estimators': 10000,\n",
              "   'learning_rate': 0.1,\n",
              "   'n_jobs': -1,\n",
              "   'proc.max_category_levels': 100,\n",
              "   'objective': 'binary:logistic',\n",
              "   'booster': 'gbtree',\n",
              "   'use_label_encoder': False},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                   model  score_val  pred_time_val   fit_time  \\\n",
              " 0   WeightedEnsemble_L2     0.8864       0.443720  71.705051   \n",
              " 1              CatBoost     0.8836       0.025799  36.035641   \n",
              " 2              LightGBM     0.8824       0.053497   1.951005   \n",
              " 3            LightGBMXT     0.8792       0.075792   2.768765   \n",
              " 4               XGBoost     0.8720       0.027042   0.668326   \n",
              " 5      RandomForestGini     0.8640       0.312669   9.969909   \n",
              " 6       NeuralNetFastAI     0.8628       0.057627  29.385520   \n",
              " 7      RandomForestEntr     0.8608       0.520466  17.410235   \n",
              " 8        ExtraTreesEntr     0.8496       0.313502   6.974835   \n",
              " 9        ExtraTreesGini     0.8496       0.314304   6.362925   \n",
              " 10       KNeighborsUnif     0.7752       0.115768   0.110614   \n",
              " 11       KNeighborsDist     0.7660       0.109834   0.102330   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.005404           1.351176            2       True   \n",
              " 1                 0.025799          36.035641            1       True   \n",
              " 2                 0.053497           1.951005            1       True   \n",
              " 3                 0.075792           2.768765            1       True   \n",
              " 4                 0.027042           0.668326            1       True   \n",
              " 5                 0.312669           9.969909            1       True   \n",
              " 6                 0.057627          29.385520            1       True   \n",
              " 7                 0.520466          17.410235            1       True   \n",
              " 8                 0.313502           6.974835            1       True   \n",
              " 9                 0.314304           6.362925            1       True   \n",
              " 10                0.115768           0.110614            1       True   \n",
              " 11                0.109834           0.102330            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          12  \n",
              " 1           7  \n",
              " 2           4  \n",
              " 3           3  \n",
              " 4          11  \n",
              " 5           5  \n",
              " 6          10  \n",
              " 7           6  \n",
              " 8           9  \n",
              " 9           8  \n",
              " 10          1  \n",
              " 11          2  }"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1\n",
        "Probar multiples codificaciones incluida K-mers para probar sobre el archivo de prueba y mostrar el mejor resultado, adicional utilizar la operación grid search para realizar optimización de párametros"
      ],
      "metadata": {
        "id": "XcVE4M23Flzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Tomar el base de datos de 11 tumores a partir de microarrays de expresión genica y clasificarlos con los algoritmos vistos en este notebook incluido optimización de páramteros"
      ],
      "metadata": {
        "id": "RC_oGvyQGWf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Tomar el base de datos de gioblastoma y clasificarlos con los algoritmos vistos en este notebook incluido optimización de páramteros"
      ],
      "metadata": {
        "id": "OkLZ6j46JiRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 4\n",
        "Utilizar autoglon (auto Machine learning) para la base de datos de LTR en una codifiación particular"
      ],
      "metadata": {
        "id": "rObPrfVTQsxR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Clase-3-Bioinformatics-Machine-Learning.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}